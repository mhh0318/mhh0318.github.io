<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Minghui Hu | NTU</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Minghui Hu</name>
              </p>
              <p style="text-align:center">
                <name style="font-family: 'STKaiti'; font-size: 24px;">ËÉ°ÊòéËæâ</name>
              </p>
              <p>I received my PhD degree from <a href="https://www.ntu.edu.sg">Nanyang Technological University</a> in Singapore, advised by <a href="https://www3.ntu.edu.sg/home/epnsugan/">Prof. P. N. Suganthan</a>. Previousely, I received my MSc. degree in <a href="https://www.ntu.edu.sg/eee"> Electric and Electrical Engineering</a> from NTU in 2019. Parallel to my doctoral studies, I hold a position as a researcher at <a href="https://www.ntu.edu.sg/temasek-labs">Temasek Lab @ NTU</a>, under the supervision of <a href="https://www.ntu.edu.sg/temasek-labs/research-focus/research-areas/center-for-communication-and-signal-processing">Dr. Sirajudeen s/o Gulam Razul</a>.
              </p>
              <p>
                I've had the distinct privilege of collaborating with <a href="https://personal.ntu.edu.sg/astjcham/">Prof. T.J.Cham</a> and <a href="https://dr.ntu.edu.sg/cris/rp/rp02343">Prof. Dacheng Tao</a> from <a href="https://www.ntu.edu.sg/scse">NTU</a>, &nbsp;<a href="https://chuanxiaz.com/">Dr. Chuanxia Zheng</a> from <a href="https://www.robots.ox.ac.uk/~vgg/">VGG, University of Oxford</a> and <a href="https://wang-chaoyue.github.io/">Dr. Chaoyue Wang</a> from University of Sydney.
                I also had memorable experiences as a research intern <a href="https://www.sensetime.com">Sensetime Research</a>, JD Explore Academy and <a href="https://api.minimax.chat">MiniMax</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:e200008@e.ntu.edu.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/Minghui_cv.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=9jfGj64AAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/mhh0318/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/minghui-hu-b62626168/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:45%;max-width:45%">
              <a href="images/me.jpg"><img style="width:80%;max-width:100%" alt="profile photo" src="images/me.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <div class="news">
              <ul style="text-align:justify;height: 150px;">
              <li class="font"><font color="red">[2024.06]  <a target="_blank" href="https://zongrui.page/ECCV2024-GCS-BEG/">GCS</a>, a project with <a target="_blank" href="https://zongrui.page/">Zongrui</a>, is accepted by ECCV2024.</font></li>  
              <li class="font">[2024.02]  <a target="_blank" href="https://jabir-zheng.github.io/MMoT/">MMoT</a> is accepted by IJCV. Congrats <a target="_blank" href="https://jabir-zheng.github.io">Jianbin</a>.</font></li>  
              <li class="font">[2024.02]  <a target="_blank" href="https://jabir-zheng.github.io/OneMoreStep/">OneMoreStep</a> is accepted by CVPR2024.</font></li>  
              <li class="font">[2023.11] An <a target="_blank" href="https://link.springer.com/chapter/10.1007/978-981-99-8067-3_37">ICONIP2023 submission</a> wins the Best Student Award. Congrats <a target="_blank" href="https://scholar.google.com/citations?user=vEYtdJoAAAAJ&hl">Ruilin</a>.</font></li>  
              <li class="font">[2023.09] <a target="_blank" href="https://mhh0318.github.io/cocktail/">Cocktailüç∏</a> is accepted by NeurIPS2023.</font></li>
              <li class="font">[2023.08] <a target="_blank" href="https://ieeexplore.ieee.org/document/10220213/">Self-Distillation for Randomized Neural Networks</a> is accepted by T-NNLS.</font></li>
              <li class="font">[2023.07] <a target="_blank" href="https://ieeexplore.ieee.org/document/10105944">SE(2)LiO</a> is accepted by RA-L and presented at IROS2023. Congrats <a target="_blank" href="https://jabir-zheng.github.io">Jiaying Chen</a>.</font></li>
              <li class="font">[2023.01] <a target="_blank" href="https://mhh0318.github.io/unid3/">UniD3</a> is accepted by ICLR2023.</font></li>
              <li class="font">[2022.03] <a target="_blank" href="https://mhh0318.github.io/">VQ-DDM</a> is accepted by CVPR2022.</font></li>
              </ul>
              </div>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              My research focuses on generative models, multi-modality learning, and its applications in many domains, particularly 2D Image Generation. Prior to this, I was working on 
              a network model with a simple topology named randomized neural networks.
            </p>
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div id="container", style="position: relative; width: 160px; height: 160px;">
        <video id="gcs_video" src="images/gcs.mp4" width="160" loop style="position: absolute; display: none;"></video>
        <img id="angel_image" src='images/gcs.png' width="160" style="position: absolute;">
    </div>
    <script type="text/javascript">
    document.addEventListener('DOMContentLoaded', (event) => {
        const video = document.getElementById('gcs_video');
        const image = document.getElementById('angel_image');
    
        image.addEventListener('mouseover', () => {
            video.currentTime = 0; // Set video to start from the beginning
            video.style.display = 'block'; // Make the video visible
            video.play(); // Play the video
            image.style.opacity = "0"; // Make the image transparent
        });
    
        image.addEventListener('mouseout', () => {
            video.pause(); // Pause the video when mouse leaves the image
            video.style.display = 'none'; // Hide the video
            image.style.opacity = "1"; // Restore the image's opacity
        });
    });
    </script>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://zongrui.page/ECCV2024-GCS-BEG/">
      <papertitle>	Connecting Consistency Distillation to Score Distillation for Text-to-3D Generation</papertitle>
    </a>
    <br>
    <a href="https://zongrui.page/">Zongrui Li *</a>,
    <strong>Minghui Hu *</strong>,
    <a href="https://person.zju.edu.cn/en/zq">Qian Zheng</a>,
    <a href="https://personal.ntu.edu.sg/exdjiang/">Xudong Jiang</a>,
    <br>
    <em>ECCV</em>, 2024 &nbsp
    <br>
    <a href="https://zongrui.page/ECCV2024-GCS-BEG/">project page</a>
    /
    <a href="https://arxiv.org/abs/2407.13584">arXiv</a>
    /
    <a href="https://github.com/LMozart/ECCV2024-GCS-BEG">code</a>
    <p></p>
    <p>
    We analyze current SDS-based text-to-3D generation methods and propose an improved version with a bright normalizing trick for Gaussian Splatting.
    </p>
    <p style="font-size: 80%;"> * equal contribution </p>
  </td>
</tr>



<tr onmouseout="tcd_stop()" onmouseover="tcd_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='tcd_image'>
      <img src="images/tcd_1.png" width="160"></div>
      <img src='images/tcd_0.png' width="160">
    </div>
    <script type="text/javascript">
      function tcd_start() {
        document.getElementById('tcd_image').style.opacity = "1";
      }

      function tcd_stop() {
        document.getElementById('tcd_image').style.opacity = "0";
      }
      tcd_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/tcd/">
      <papertitle>Trajectory Consistency Distillation</papertitle>
    </a>
    <br>
    <a>Jianbin Zheng *</a>,
    <strong>Minghui Hu *</strong>,
    <a>Zhongyi Fan</a>,
    <a>Chaoyue Wang</a>,
    <a>Changxing Ding</a>,
    <a>Dacheng Tao</a>,
    <a>Tat-Jen Cham</a>
    <br>
    <em>Tech Report</em>, 2024 &nbsp
    <br>
    <a href="https://mhh0318.github.io/tcd/">project page</a>
    /
    <a href="https://arxiv.org/abs/2402.19159">arXiv</a>
    /
    <a href="https://github.com/jabir-zheng/TCD">code</a>
    /
    <a href="https://huggingface.co/h1t/TCD-SDXL-LoRA">HF Model</a>
    /
    <a href="https://huggingface.co/spaces/h1t/TCD">HF Space</a>
    <p></p>
    <p>
    We distill a consistency model based on diffusion trajectory to improve the sample quality.
    </p>
    <p style="font-size: 80%;"> * equal contribution </p>
  </td>
</tr>

<tr onmouseout="oms_stop()" onmouseover="oms_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='oms_image'>
      <img src="images/oms_0.png" width="160"></div>
      <img src='images/oms_1.png' width="160">
    </div>
    <script type="text/javascript">
      function oms_start() {
        document.getElementById('oms_image').style.opacity = "1";
      }

      function oms_stop() {
        document.getElementById('oms_image').style.opacity = "0";
      }
      oms_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://jabir-zheng.github.io/OneMoreStep/">
      <papertitle>One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion Schedule Flaws and Enhancing Low-Frequency Controls</papertitle>
    </a>
    <br>
    <strong>Minghui Hu</strong>,
    <a href="https://jabir-zheng.github.io">Jianbin Zheng</a>,
    <a href="https://chuanxiaz.com/">Chuanxia Zheng</a>,
    <a href="https://wang-chaoyue.github.io/">Chaoyue Wang</a>,
    <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a>,
    <a href="https://personal.ntu.edu.sg/astjcham/">Tat-Jen Cham</a>
    <br>
    <em>CVPR</em>, 2024 &nbsp
    <br>
    <a href="https://jabir-zheng.github.io/OneMoreStep/">project page</a>
    /
    <a href="http://arxiv.org/abs/2311.15744">arXiv</a>
    /
    <!-- <a href="data/Cocktail.pdf">PDF</a>
    / -->
    <a href="https://github.com/mhh0318/OneMoreStep">code</a>
    /
    <a href="https://huggingface.co/h1t/oms_b_openclip_xl">HF Model</a>
    /
    <a href="https://huggingface.co/spaces/h1t/oms_sdxl_lcm">HF Space</a>
    <p></p>
    <p>
    We develop a versatile plug-and-play module to fix the scheduler flaws for diffusion models.
    </p>
  </td>
</tr>


<tr onmouseout="cocktail_stop()" onmouseover="cocktail_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='cocktail_image'>
      <img src="images/jb_1.png" width="160"></div>
      <img src='images/jb_0.png' width="160">
    </div>
    <script type="text/javascript">
      function cocktail_start() {
        document.getElementById('cocktail_image').style.opacity = "1";
      }

      function cocktail_stop() {
        document.getElementById('cocktail_image').style.opacity = "0";
      }
      cocktail_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/cocktail/">
      <papertitle>Cocktailüç∏: Mixing Multi-Modality Controls for Text-Conditional Image Generation</papertitle>
    </a>
    <br>
    <strong>Minghui Hu</strong>,
    <a href="https://jabir-zheng.github.io">Jianbin Zheng</a>,
    <a href="https://daqingliu.github.io/">Daqing Liu</a>,
    <a href="https://chuanxiaz.com/">Chuanxia Zheng</a>,
    <a href="https://wang-chaoyue.github.io/">Chaoyue Wang</a>,
    <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a>,
    <a href="https://personal.ntu.edu.sg/astjcham/">Tat-Jen Cham</a>
    <br>
    <em>NeurIPS</em>, 2023 &nbsp
    <br>
    <a href="https://mhh0318.github.io/cocktail/">project page</a>
    /
    <a href="https://arxiv.org/abs/2306.00964">arXiv</a>
    /
    <a href="https://github.com/mhh0318/Cocktail">code</a>
    /
    <a href="https://huggingface.co/h1t/cocktail">HF Model</a>
    <p></p>
    <p>
    We develop a generalized HypreNetwork for multi-modality control based on text-to-image generative model.
    </p>
  </td>
</tr>
      
<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src='images/SDRVFL.png' width="160">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/">
      <papertitle>Self-Distillation for Randomized Neural Networks</papertitle>
    </a>
    <br>
    <strong>Minghui Hu</strong>,
    <a href="https://scholar.google.com.sg/citations?user=PrIHu7QAAAAJ&hl=en">Ruobin Gao</a>,
    <a href="https://www3.ntu.edu.sg/home/epnsugan/">P.N.Suganthan</a>,
    <br>
    <em>T-NNLS</em> &nbsp
    <br>
    <!-- <a href="https://mhh0318.github.io/">project page</a>
    / -->
    <a href="https://ieeexplore.ieee.org/abstract/document/10220213/">IEEE</a>
    /
    <a href="https://github.com/mhh0318/KDRVFL">Code</a>
    <p></p>
    <p>
        We integrate self-distillation into the randomized neural network to improve the generalization performance.
    </p>
  </td>
</tr>


<tr onmouseout="mmot_stop()" onmouseover="mmot_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='mmot_image'>
      <img src="images/mmot_0.png" width="160"></div>
      <img src='images/mmot_1.png' width="160">
    </div>
    <script type="text/javascript">
      function mmot_start() {
        document.getElementById('mmot_image').style.opacity = "1";
      }

      function mmot_stop() {
        document.getElementById('mmot_image').style.opacity = "0";
      }
      mmot_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://jabir-zheng.github.io/MMoT/">
      <papertitle>MMoT: Mixture-of-Modality-Tokens Transformer for Composed Multimodal Conditional Image Synthesis</papertitle>
    </a>
    <br>
    <a href="https://jabir-zheng.github.io">Jianbin Zheng</a>,
    <a href="https://daqingliu.github.io/">Daqing Liu</a>,
    <a href="https://wang-chaoyue.github.io/">Chaoyue Wang</a>,
    <strong>Minghui Hu</strong>,
    <a href="https://dblp.org/pid/254/9451.html">Zuopeng Yang</a>,
    <a href=" ">Changxing Ding</a>,
    <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a>,
    <br>
    <em>IJCV</em> &nbsp
    <br>
    <a href="https://jabir-zheng.github.io/MMoT/">project page</a>
    /
    <a href="https://arxiv.org/abs/2305.05992">arXiv</a>
    <!-- /
    <a href="data/MMoT.pdf">PDF</a> -->
    <p></p>
    <p>
      We introduce a Mixture-of-Modality-Tokens Transformer (MMoT) that adaptively fuses fine-grained multimodal control signals for multi-modality image generation.
    </p>
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src='images/ral.png' width="160">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/">
      <papertitle>Versatile LiDAR-Inertial Odometry with SE(2) Constraints for Ground Vehicles</papertitle>
    </a>
    <br>
    <a>Jiaying Chen</a>,
    <a href="https://wanghan.pro/">Han Wang</a>,
    <strong>Minghui Hu</strong>,
    <a href="https://www3.ntu.edu.sg/home/epnsugan/">P.N.Suganthan</a>,
    <br>
    <em>RA-L & IROS</em>, 2023 &nbsp
    <br>
    <!-- <a href="https://mhh0318.github.io/">project page</a>
    / -->
    <a href="https://ieeexplore.ieee.org/document/10105944">IEEE</a>
    <!-- /
    <a href="data/MMoT.pdf">PDF</a> -->
    <p></p>
    <p>
      We propose a hybrid LiDAR-inertial SLAM framework that leverages both the on-board perception system and prior information such as motion dynamics to improve localization performance.
    </p>
  </td>
</tr>


<tr onmouseout="dtw_stop()" onmouseover="dtw_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='dtw_image'>
      <img src="images/dtw_0.png" width="160"></div>
      <img src='images/dtw_1.png' width="160">
    </div>
    <script type="text/javascript">
      function dtw_start() {
        document.getElementById('dtw_image').style.opacity = "1";
      }

      function dtw_stop() {
        document.getElementById('dtw_image').style.opacity = "0";
      }
      dtw_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/">
      <papertitle>Class-Incremental Learning on Multivariate Time Series Via Shape-Aligned Temporal Distillation</papertitle>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=7rbhsrEAAAAJ">Zhongzheng Qiao</a>,
    <strong>Minghui Hu</strong>,
    <a href="https://personal.ntu.edu.sg/exdjiang/">Xudong Jiang</a>,
    <a href="https://www3.ntu.edu.sg/home/epnsugan/">P.N.Suganthan</a>,
    <a href="https://rsavitha.webs.com/">Ramasamy Savitha</a>,
    <br>
    <em>ICASSP</em>, 2023 &nbsp
    <br>
    <!-- <a href="https://mhh0318.github.io/">project page</a>
    / -->
    <a href="https://ieeexplore.ieee.org/abstract/document/10094960">IEEE</a>
    <!-- /
    <a href="data/MMoT.pdf">PDF</a> -->
    <p></p>
    <p>
      We propose to exploit Soft-Dynamic Time Warping (Soft-DTW) for knowledge distillation, which aligns the feature maps along the temporal dimension before calculating the discrepancy.
    </p>
  </td>
</tr>


<tr onmouseout="unid3_stop()" onmouseover="unid3_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='unid3_image'>
      <img src="images/unid3_clean.png" width="160"></div>
      <img src='images/unid3_noisy.png' width="160">
    </div>
    <script type="text/javascript">
      function unid3_start() {
        document.getElementById('unid3_image').style.opacity = "1";
      }

      function unid3_stop() {
        document.getElementById('unid3_image').style.opacity = "0";
      }
      unid3_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/unid3/">
      <papertitle>Unified Discrete Diffusion for Simultaneous Vision-Language Generation</papertitle>
    </a>
    <br>
    <strong>Minghui Hu</strong>,
		<a href="https://chuanxiaz.com/">Chuanxia Zheng</a>,
    Zuopeng Yang,
    <a href="https://personal.ntu.edu.sg/astjcham/">Tat-Jen Cham</a>,
    <a href="https://wang-chaoyue.github.io/">Chaoyue Wang</a>,
    <a href="https://dblp.org/pid/254/9451.html">Zuopeng Yang</a>,
    <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a>,
    <a href="https://www3.ntu.edu.sg/home/epnsugan/">P.N.Suganthan</a>
    <br>
    <em>ICLR</em>, 2023 &nbsp
    <br>
    <a href="https://mhh0318.github.io/unid3/">project page</a>
    /
    <a href="https://arxiv.org/abs/2211.14842">arXiv</a>
    /
    <a href="data/UniD3.pdf">PDF</a>
    <p></p>
    <p>
    We construct a unified discrete diffusion model for simultaneous vision-language generation.
    </p>
  </td>
</tr>
		  
<tr onmouseout="usrvfl_stop()" onmouseover="usrvfl_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='usrvfl_image'>
      <img src="images/usrvfl_0.png" width="160"></div>
      <img src='images/usrvfl_1.png' width="160">
    </div>
    <script type="text/javascript">
      function usrvfl_start() {
        document.getElementById('usrvfl_image').style.opacity = "1";
      }

      function usrvfl_stop() {
        document.getElementById('usrvfl_image').style.opacity = "0";
      }
      vqddm_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/VQDDM/">
      <papertitle>Representation Learning Using Deep Random Vector Functional Link Networks for Clustering</papertitle>
    </a>
    <br>
    <strong>Minghui Hu</strong>,
    <a href="https://www3.ntu.edu.sg/home/epnsugan/">P.N.Suganthan</a>
    <br>
    <em>PR</em> &nbsp
    <br>
    <!-- <a href="https://mhh0318.github.io/unid3/">project page</a> -->
    <!-- / -->
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322002254">Elsevier</a>
    <p></p>
    <p>
    We use manifold regularisation to learn the representation from the randomised networks.
    </p>
  </td>
</tr>

<tr onmouseout="vqddm_stop()" onmouseover="vqddm_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='vqddm_image'>
      <img src="images/vqddm_mod.png" width="160"></div>
      <img src='images/vqddm_raw.png' width="160">
    </div>
    <script type="text/javascript">
      function vqddm_start() {
        document.getElementById('vqddm_image').style.opacity = "1";
      }

      function vqddm_stop() {
        document.getElementById('vqddm_image').style.opacity = "0";
      }
      vqddm_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://mhh0318.github.io/VQDDM/">
      <papertitle>Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation</papertitle>
    </a>
    <br>
    <strong>Minghui Hu</strong>,
		<a href="https://scholar.google.com/citations?user=7CobseIAAAAJ&hl=en">Yujie Wang</a>,
    <a href="https://personal.ntu.edu.sg/astjcham/">Tat-Jen Cham</a>,
    <a href="http://marsyang.site/">Jianfei Yang</a>,
    <a href="https://www3.ntu.edu.sg/home/epnsugan/">P.N.Suganthan</a>
    <br>
    <em>CVPR</em>, 2022 &nbsp
    <br>
    <!-- <a href="https://mhh0318.github.io/unid3/">project page</a> -->
    <!-- / -->
    <a href="https://arxiv.org/abs/2112.01799">arXiv</a>
    /
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Global_Context_With_Discrete_Diffusion_in_Vector_Quantised_Modelling_for_CVPR_2022_paper.pdf">PDF</a>
    <p></p>
    <p>
    Instead of AutoRegresive Transformers, we use Discrete Diffusion Model to obtain a better global context for image generation.
    </p>
  </td>
</tr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
  <tr>
    <td>
      <heading>Academic Services</heading>
      <p><font size="4"><b>Conference Program Committee Member</b></font></p>
    <table>
      <tr><td>CVPR</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2022&nbsp;-&nbsp;2024</td></tr>
      <tr><td>ICCV</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2023</td></tr>
      <tr><td>ECCV</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2024</td></tr>
      <tr><td>ACM MM</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2024</td></tr>
      <tr><td>NeurIPS</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2023,&nbsp;2024</td></tr>
      <tr><td>ICLR</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2023,&nbsp;2024</td></tr>
      <tr><td>ACCV</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2024</td></tr>
      <tr><td>ICASSP</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2023,&nbsp;2024</td></tr>
      <tr><td>IJCNN</td><td>&nbsp;&nbsp;&nbsp;&nbsp;2020&nbsp;-&nbsp;2024</td></tr>
    </table>
      <p><font size="4"><b>Journal Reviewer</b></font></p>
      <p>T-NNLS, T-Cyb, PR, NeuNet, Neucom, ASOC, EAAI, IJCV</p>
    </td>
  </tr>
</tbody></table>


<table align="right", style="width:20%;border:0px;border-spacing:0px;border-collapse:separate;vertical-align: bottom;"><tbody>
  <tr>
    <td style="padding:15px;width:10%;vertical-align:middle">
      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=afeIQSK3lal5Bc8L-8eaHbv1W5ZtwqTyvLzoEYsw1R4">
      </script>
    </td>
    </tr>
    </tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td>
    <br>
    <p align="right">
      <font size="2">
      Yep it's another <a href="https://jonbarron.info">Jon Barron</a> website. <br>
      Last updated Jul. 2024.
  </font>
    </p>
    </td>
  </tr>
</table>




      </td>
    </tr>
  </table>
</body>

</html>
